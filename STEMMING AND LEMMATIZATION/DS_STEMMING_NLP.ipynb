{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOvPom2NoCdRSMI/HZjJCTp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sonupp13/NATURAL-LANGUAGE-PROCESSING/blob/main/STEMMING%20AND%20LEMMATIZATION/DS_STEMMING_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stemming\n",
        "\n",
        "The idea of stemming is a sort of normalizing method.\n",
        "Many variations of words carry the same meaning, other than when tense is involved.\n",
        "The reason why we stem is to shorten the lookup, and normalize sentences.\n",
        "\n",
        "Consider:\n",
        "I was taking a ride in the car.\n",
        "I was riding in the car.\n",
        "This sentence means the same thing. in the car is the same.\n",
        "I was is the same. the ing denotes a clear past-tense in both cases\n",
        "so is it truly necessary to differentiate between ride and riding,\n",
        "in the case of just trying to figure out the meaning of what this past-tense activity was"
      ],
      "metadata": {
        "id": "kN_cn6ltLXFa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "WordNet is a lexical database for the English language, often used in natural language processing and computational linguistics.\n",
        "It's a large, machine-readable database of words and their semantic relationships.\n",
        "you can use the WordNetLemmatizer to find the base or dictionary form (lemma) of words based on their part of speech.\n",
        "\n",
        "\n",
        "**The punkt module in NLTK refers to a tokenizer for splitting text into sentences.\n",
        "Tokenization is the process of breaking down a text into smaller units, which can be words or sentences, depending on the level of tokenization**"
      ],
      "metadata": {
        "id": "P4Y9TFR_MGty"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#stemming\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize,sent_tokenize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQxE4-NiMZRd",
        "outputId": "de300951-56c8-4dc5-c169-157c54277603"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ps= PorterStemmer()\n",
        "ps"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kItw2-3gM_vI",
        "outputId": "5b423126-b880-48f7-b1a8-3f4cfaeb147d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PorterStemmer>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example=[\"python\",\"pythoner\",\"pythoning\",\"pythoned\",\"pythonly\",\"simply\"]\n",
        "for w in example:\n",
        "  print(ps.stem(w))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YWzEmUFMddA",
        "outputId": "fc26f247-beed-47e6-b821-0924df839630"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python\n",
            "python\n",
            "python\n",
            "python\n",
            "pythonli\n",
            "simpli\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "sentence"
      ],
      "metadata": {
        "id": "Wpn4cxzwOx5o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"It is important to by very pythonly while you are pythoning with python. All pythoners have pythoned poorly at least once.\"\n",
        "\n",
        "words= word_tokenize(text)\n",
        "print(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khOrwQ1HOENZ",
        "outputId": "e92fceee-d200-48cf-f1f3-81d2b43703f4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['It', 'is', 'important', 'to', 'by', 'very', 'pythonly', 'while', 'you', 'are', 'pythoning', 'with', 'python', '.', 'All', 'pythoners', 'have', 'pythoned', 'poorly', 'at', 'least', 'once', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for w in words :\n",
        "  print(ps.stem(w))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwoGqao8OnM2",
        "outputId": "a63e1164-117b-4c0c-85a1-b5deb0c52694"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "it\n",
            "is\n",
            "import\n",
            "to\n",
            "by\n",
            "veri\n",
            "pythonli\n",
            "while\n",
            "you\n",
            "are\n",
            "python\n",
            "with\n",
            "python\n",
            ".\n",
            "all\n",
            "python\n",
            "have\n",
            "python\n",
            "poorli\n",
            "at\n",
            "least\n",
            "onc\n",
            ".\n"
          ]
        }
      ]
    }
  ]
}