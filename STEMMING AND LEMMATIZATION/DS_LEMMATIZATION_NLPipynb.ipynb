{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNV1LmS7c+PRMHOb9kP6hjO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sonupp13/NATURAL-LANGUAGE-PROCESSING/blob/main/STEMMING%20AND%20LEMMATIZATION/DS_LEMMATIZATION_NLPipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lemmatizing\n",
        "\n",
        "A very similar operation to stemming is called lemmatizing.\n",
        "The major difference between these is, as you saw earlier,\n",
        "stemming can often create non-existent words, whereas lemmas are actual words.\n",
        "So, your root stem, meaning the word you end up with,\n",
        "is not something you can just look up in a dictionary, but you can look up a lemma.\n",
        "Some times you will wind up with a very similar word, but sometimes,\n",
        "you will wind up with a completely different word."
      ],
      "metadata": {
        "id": "mEVHmlH1RD56"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SeoHJE4cQNb1",
        "outputId": "f9dbc0a5-f040-4abf-82f9-1c018d06dc15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "print(lemmatizer.lemmatize(\"cats\"))\n",
        "print(lemmatizer.lemmatize(\"cacti\"))\n",
        "print(lemmatizer.lemmatize(\"geese\"))\n",
        "print(lemmatizer.lemmatize(\"rocks\"))\n",
        "print(lemmatizer.lemmatize(\"python\"))\n",
        "print(lemmatizer.lemmatize(\"better\", pos=\"a\"))\n",
        "print(lemmatizer.lemmatize(\"best\", pos=\"a\"))\n",
        "print(lemmatizer.lemmatize(\"run\"))\n",
        "print(lemmatizer.lemmatize(\"ran\",'v'))\n",
        "\n",
        "# Inference :\n",
        "# But lemmatization has limits.\n",
        "# For example, Porter stems both happiness and happy to happi,\n",
        "# while WordNet lemmatizes the two words to themselves.\n",
        "# The WordNet lemmatizer also requires specifying the word’s part of speech\n",
        "# otherwise, it assumes the word is a noun.\n",
        "# Finally, lemmatization cannot handle unknown words: for example,\n",
        "# Porter stems both iphone and iphones to iphon, while WordNet lemmatizes both words to themselves.\n",
        "# In the example of shoe and shoes, we probably want to treat the two forms identically.\n",
        "# But we wouldn’t want to do the same for the words logistic(Mathematical term) and logistics(Mechanical term),\n",
        "# which mean very different things despite their apparent similarity.\n",
        "# Nor would we want to equate the words universe and university,\n",
        "# even though both words derive from the same Latin root."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Zt1NgJhRPhk",
        "outputId": "f7f49f5b-58fd-4680-dc2a-a40c94386f37"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cat\n",
            "cactus\n",
            "goose\n",
            "rock\n",
            "python\n",
            "good\n",
            "best\n",
            "run\n",
            "run\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(lemmatizer.lemmatize(\"happier\", pos=\"a\"))  # Output: happy ,"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNxLZYB1RWXw",
        "outputId": "058f8181-64b5-4201-f3e0-22a197c82001"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "happy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(lemmatizer.lemmatize(\"children\", pos=\"n\"))  # Output: child\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0N0EI2o0RY2v",
        "outputId": "699e2aa2-d89c-4ca3-c057-a516172d9030"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "child\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pos=part of speech\n",
        "# a=adverb\n",
        "# n=noun\n",
        "# v=verb"
      ],
      "metadata": {
        "id": "tsHwUx1GRbSX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}