{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN7TJlAiTUsdXiwUegnEghS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sonupp13/NATURAL-LANGUAGE-PROCESSING/blob/main/DS_STOP_WORDS_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stop Words\n",
        "\n",
        "We cease analysis if we detect words that are commonly used sarcastically & stop immediately.\n",
        "\n",
        "Sarcastic words, or phrases are going to vary by lexicon and corpus.\n",
        "\n",
        "We'll be considering stop words as words that just contain no meaning, we want to remove them."
      ],
      "metadata": {
        "id": "khGHnEYyeyaH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPol-JpIe56i",
        "outputId": "b7b1e478-e162-41c5-9415-5e666b3043fc"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List of Stop Words already set in a library\n",
        "print(set(stopwords.words('english')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-QBK5Jpf6QE",
        "outputId": "4cd52c71-2cf7-47db-d7ab-8809e50b28a8"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"aren't\", 'were', 'they', 'so', 'who', 'then', 's', 'is', 'theirs', 'just', 'mustn', 'you', 'himself', 'ma', 'herself', \"isn't\", 'by', 'once', 'whom', 'itself', 'should', \"wasn't\", 'me', 'being', 'shan', 'yourselves', 'hasn', 'most', 'yourself', 'nor', 'to', 'ourselves', 'of', \"won't\", 'and', 'here', 'll', 'this', 'through', 'our', 'hadn', 'myself', 'weren', \"you're\", 'against', 'off', \"mustn't\", 'while', 'which', 'these', 'on', 'him', 'about', 'y', \"mightn't\", 'won', 'why', 'his', 'doesn', \"should've\", 't', 'am', \"weren't\", 'during', 'had', 'from', 'yours', 'if', 'we', 'aren', 'no', \"that'll\", 'having', 'm', 'further', 'ain', 'any', 'd', 'he', 'i', \"you'd\", 'it', \"haven't\", 'she', 'isn', 'do', \"wouldn't\", 'very', 'don', 'been', 'up', 'o', 'out', \"doesn't\", 'couldn', 'what', 'until', 'wasn', 'them', 'are', 'how', \"hasn't\", 'in', \"don't\", 'ours', 'that', 'before', 'few', \"you've\", 'have', 'other', \"she's\", \"shan't\", 'because', 'as', 'only', 'at', 'above', 'over', 'did', 'own', 'such', 'there', 'does', 'all', 'a', 'too', 'than', 'with', 'will', 'now', \"couldn't\", 'or', 'your', 'didn', \"it's\", 'can', 'where', 've', 'needn', 'after', 're', 'each', 'doing', 'down', \"shouldn't\", 'some', 'again', 'both', \"needn't\", 'wouldn', 'an', 'when', 'below', 'haven', 'hers', 'mightn', 'shouldn', 'its', 'for', 'between', 'more', 'themselves', 'into', 'was', 'has', 'their', \"you'll\", 'those', 'same', 'the', 'my', 'be', 'her', \"hadn't\", 'but', 'under', 'not', \"didn't\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text= \"This is a sample sentence, showing off the stop words filtration.\"\n",
        "stop_words = set(stopwords.words('english'))\n",
        "filtered=[]\n",
        "words= word_tokenize(text)\n",
        "for w in words:\n",
        "  if w not  in stop_words:\n",
        "   filtered.append(w)\n",
        "#filtered_sentence = [w for w in word_tokens if not w in stop_words]   #List Comprehension\n",
        "print(\"text\")\n",
        "print(text)\n",
        "print(\"\\n\")\n",
        "print(words)\n",
        "print(\"\\n\")\n",
        "print(\"FILTERED SENTENCE i.e, stop words removed\")\n",
        "print(filtered)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5s14XiI4g8eY",
        "outputId": "5af69005-ce8b-4651-8c79-3d52afae3dc6"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text\n",
            "This is a sample sentence, showing off the stop words filtration.\n",
            "\n",
            "\n",
            "['This', 'is', 'a', 'sample', 'sentence', ',', 'showing', 'off', 'the', 'stop', 'words', 'filtration', '.']\n",
            "\n",
            "\n",
            "FILTERED SENTENCE i.e, stop words removed\n",
            "['This', 'sample', 'sentence', ',', 'showing', 'stop', 'words', 'filtration', '.']\n"
          ]
        }
      ]
    }
  ]
}